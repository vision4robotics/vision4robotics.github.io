<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision4robotics</title>
    <link>https://vision4robotics.github.io/authors/bowen-li/</link>
    <description>Recent content on Vision4robotics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; 2019 - {year} Vision4robotics. All Rights Reserved.</copyright>
    <lastBuildDate>Sat, 26 Nov 2022 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://vision4robotics.github.io/authors/bowen-li/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scale-Aware Siamese Object Tracking for Vision-Based UAM Approaching</title>
      <link>https://vision4robotics.github.io/publication/2022_tii_siamsa/</link>
      <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_tii_siamsa/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;SiamPSA_workflow&#34; /&gt;
&lt;small&gt;Demonstration of the vision-based UAM approaching system and qualitative comparison.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PVT&#43;&#43;: A Simple End-to-End Latency-Aware Visual Tracking Framework</title>
      <link>https://vision4robotics.github.io/publication/2022_arxiv_pvt&#43;&#43;/</link>
      <pubDate>Sun, 20 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_arxiv_pvt&#43;&#43;/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;workflow&#34; /&gt;
&lt;small&gt;&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention</title>
      <link>https://vision4robotics.github.io/publication/2022_iros_siamsa/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_iros_siamsa/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;SiamPSA_workflow&#34; /&gt;
&lt;small&gt;An overview of the proposed Siamese tracking with pairwise scale-channel attention (SiamPSA) for UAM approaching.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis</title>
      <link>https://vision4robotics.github.io/publication/2022_grsm_siam/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_grsm_siam/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;leading_trackers&#34; /&gt;
&lt;small&gt;The category of leading-edge Siamese trackers over the years.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>All-Day Object Tracking for Unmanned Aerial Vehicle</title>
      <link>https://vision4robotics.github.io/publication/2022_tmc_adtrack/</link>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_tmc_adtrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;ADTrack_workflow&#34; /&gt;
&lt;small&gt;Pipeline of ADTrack.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tracker Meets Night: A Transformer Enhancer for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_ral_sct/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_ral_sct/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;Star_plot&#34; /&gt;
&lt;small&gt;Overall performance of SOTA trackers with the proposed SCT enabled (markers in a dark color) or not (markers in a light color) in the newly constructed nighttime UAV tracking benchmark&amp;mdash;DarkTrack2021. SCT significantly boosts the nighttime tracking performance of trackers in a plug-and-play manner.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HiFT: Hierarchical Feature Transformer for Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iccv_hift/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iccv_hift/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Overview of the HiFT tracker.&lt;/small&gt;
&lt;img src=&#34;comparison.png&#34; alt=&#34;comparison&#34; /&gt;
&lt;small&gt;Fig. 2 Framework of the hierarchical feature transformer.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DarkLighter: Light Up the Darkness for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_darklighter/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_darklighter/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking performance comparison in a typical dark scene with the
proposed DarkLighter module activated (in red) or not (in pink).&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SiamAPN&#43;&#43;: Siamese Attentional Aggregation Network for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of the SiamAPN++ tracker.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation</title>
      <link>https://vision4robotics.github.io/publication/2021_grsm_cfmg/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_grsm_cfmg/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;IBRI_workflow&#34; /&gt;
&lt;small&gt;General tracking structure of DCF-based methods onboard the UAV platform, which can be divided into the training stage, model update, and detection stage.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predictive Visual Tracking: A New Benchmark and Baseline Approach</title>
      <link>https://vision4robotics.github.io/publication/2021_arxiv_pvt/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_arxiv_pvt/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;ADTrack_workflow&#34; /&gt;
&lt;small&gt;&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_adtrack/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_adtrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Overall framework of the proposed ADTrack. ADTrack includes 3 stages: pretreatment, training, and detection, which are marked out by boxes in different colors. Dual filters, i.e., context filter and target-focused filter, training and detection follow routes in different colors. It can be seen that the final response shaded noises in context response, which indicates the validity of proposed dual filter.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://vision4robotics.github.io/authors/bowen-li/</link>
      <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/authors/bowen-li/</guid>
      <description>&lt;p&gt;Bowen Li received his B.Eng. degree in Mechanical Engineering from Tongji University, Shanghai, China, in 2022. He is currently pursuing the PhD degree in Robotics at Carnegie Mellon University (CMU), USA. His research interests include robotics, artificial intelligence, and computer vision.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
