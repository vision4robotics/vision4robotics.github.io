<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision4robotics</title>
    <link>https://vision4robotics.github.io/authors/guangze-zheng/</link>
    <description>Recent content on Vision4robotics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; 2019 - {year} Vision4robotics. All Rights Reserved.</copyright>
    <lastBuildDate>Sat, 11 Mar 2023 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://vision4robotics.github.io/authors/guangze-zheng/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cascaded Denoising Transformer for UAV Nighttime Tracking</title>
      <link>https://vision4robotics.github.io/publication/2023_ral_cdt/</link>
      <pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2023_ral_cdt/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;Star_plot&#34; /&gt;
&lt;small&gt;Overview of our CDT.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SGDViT: Saliency-Guided Dynamic Vision Transformer for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2023_icra_sgdvit/</link>
      <pubDate>Sun, 15 Jan 2023 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2023_icra_sgdvit/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Overview of the proposed SGDViT tracker.The parts from the left to right are the feature extraction network, object saliency mining network, feature adjustment sampling network, saliency filtering Transformer, and classification &amp;amp; regression network, respectively.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scale-Aware Siamese Object Tracking for Vision-Based UAM Approaching</title>
      <link>https://vision4robotics.github.io/publication/2022_tii_siamsa/</link>
      <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_tii_siamsa/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;SiamPSA_workflow&#34; /&gt;
&lt;small&gt;Demonstration of the vision-based UAM approaching system and qualitative comparison.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeconNet: End-to-End Decontaminated Network for Vision-Based Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_tgrs_deconnet/</link>
      <pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_tgrs_deconnet/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;workflow&#34; /&gt;
&lt;small&gt;Overview of the proposed DeconNet.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>End-to-End Feature Decontaminated Network for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_iros_fdnt/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_iros_fdnt/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;AFRT&#34; /&gt;
&lt;small&gt;Overview of the proposed FDNT tracker.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HighlightNet: Highlighting Low-Light Potential Features for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_iros_highlightnet/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_iros_highlightnet/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;HighlightNet&#34; /&gt;
&lt;small&gt;Overview of our HighlightNet pipeline.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise Scale-Channel Attention</title>
      <link>https://vision4robotics.github.io/publication/2022_iros_siamsa/</link>
      <pubDate>Thu, 30 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_iros_siamsa/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;SiamPSA_workflow&#34; /&gt;
&lt;small&gt;An overview of the proposed Siamese tracking with pairwise scale-channel attention (SiamPSA) for UAM approaching.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aviation Fastener Rotation Detection for Intelligent Optical Perception with Edge Computing</title>
      <link>https://vision4robotics.github.io/publication/2022_jao_kunhui/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_jao_kunhui/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;workflow&#34; /&gt;
&lt;small&gt;Lightweight aviation fastener rotation detection method.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis</title>
      <link>https://vision4robotics.github.io/publication/2022_grsm_siam/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_grsm_siam/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;leading_trackers&#34; /&gt;
&lt;small&gt;The category of leading-edge Siamese trackers over the years.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised Domain Adaptation for Nighttime Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_cvpr_udat/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_cvpr_udat/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt; Illustration of the proposed unsupervised domain adaptation framework for nighttime aerial tracking.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tracker Meets Night: A Transformer Enhancer for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_ral_sct/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_ral_sct/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;Star_plot&#34; /&gt;
&lt;small&gt;Overall performance of SOTA trackers with the proposed SCT enabled (markers in a dark color) or not (markers in a light color) in the newly constructed nighttime UAV tracking benchmark&amp;mdash;DarkTrack2021. SCT significantly boosts the nighttime tracking performance of trackers in a plug-and-play manner.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DarkLighter: Light Up the Darkness for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_darklighter/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_darklighter/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking performance comparison in a typical dark scene with the
proposed DarkLighter module activated (in red) or not (in pink).&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_mscf_tracker/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_mscf_tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking procedure of the proposed MSCF tracker. Dashed boxes denote the variables to be solved in the main regression. As MTF in the red
box is generated from search region in frame k, it is applied to adjust the altitude value of the cruciform pedestal.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://vision4robotics.github.io/authors/guangze-zheng/</link>
      <pubDate>Sat, 11 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/authors/guangze-zheng/</guid>
      <description>&lt;p&gt;Guangze Zheng received his B.Eng. degree in Mechanical Engineering from Tongji University, Shanghai, China, in 2022. He is currently pursuing the PhD degree in Computer Science at HongKong University (HKU), China. His research interests include visual object tracking and machine learning.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
