<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision4robotics</title>
    <link>https://vision4robotics.github.io/authors/ziang-cao/</link>
    <description>Recent content on Vision4robotics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; 2019 - {year} Vision4robotics. All Rights Reserved.</copyright>
    <lastBuildDate>Thu, 22 Jul 2021 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://vision4robotics.github.io/authors/ziang-cao/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HiFT: Hierarchical Feature Transformer for Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iccv_hift/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iccv_hift/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Overview of the HiFT tracker.&lt;/small&gt;
&lt;img src=&#34;comparison.png&#34; alt=&#34;comparison&#34; /&gt;
&lt;small&gt;Fig. 2 Framework of the hierarchical feature transformer.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DarkLighter: Light up the Darkness for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_darklighter/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_darklighter/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking performance comparison in a typical dark scene with the
proposed DarkLighter module activated (in red) or not (in pink).&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SiamAPN&#43;&#43;: Siamese Attentional Aggregation Network for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of the SiamAPN++ tracker.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network</title>
      <link>https://vision4robotics.github.io/publication/2021_tgrs_siamapn_ext/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tgrs_siamapn_ext/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;SiamAPN_workflow&#34; /&gt;
&lt;small&gt;The workflow of SiamAPN. It is composed of four subnetworks and two stages, i.e., feature extraction network, feature fusion network, anchor proposal network, and classification&amp;amp;regression network. Stage-1 includes feature extraction network and anchor proposal network (APN). Stage-2 contains feature fusion network and classification&amp;amp;regression network.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Anchor Proposal Network for High-Speed Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_siamapn/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_siamapn/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of SiamAPN tracker. It composes of four subnetworks, i.e., feature extraction network, feature fusion network, anchor proposal network (APN), and muti-classificationÂ®ression network.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://vision4robotics.github.io/authors/ziang-cao/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/authors/ziang-cao/</guid>
      <description>&lt;p&gt;Ziang Cao is an undergraduate student at Tongji University and currently pursuing B.Eng. degree in Vehicle Engineering. His research interests include unmanned aerial vehicle and visual object tracking.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
