<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision4robotics</title>
    <link>https://vision4robotics.github.io/</link>
    <description>Recent content on Vision4robotics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; 2019 - {year} Vision4robotics. All Rights Reserved.</copyright>
    <lastBuildDate>Wed, 02 Mar 2022 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://vision4robotics.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TCTrack: Temporal Contexts for Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_cvpr_tctrack/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_cvpr_tctrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt;Overview of our framework..&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised Domain Adaptation for Nighttime Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_cvpr_udat/</link>
      <pubDate>Wed, 02 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_cvpr_udat/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt; Illustration of the proposed unsupervised domain adaptation framework for nighttime aerial tracking.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_icra_ad2attack/</link>
      <pubDate>Tue, 01 Feb 2022 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_icra_ad2attack/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Overview of our Ad2Attack pipeline.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tracker Meets Night: A Transformer Enhancer for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2022_ral_sct/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2022_ral_sct/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;Star_plot&#34; /&gt;
&lt;small&gt;Overall performance of SOTA trackers with the proposed SCT enabled (markers in a dark color) or not (markers in a light color) in the newly constructed nighttime UAV tracking benchmark&amp;mdash;DarkTrack2021. SCT significantly boosts the nighttime tracking performance of trackers in a plug-and-play manner.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stereo Orientation Prior for UAV Robust and Accurate Visual Odometry</title>
      <link>https://vision4robotics.github.io/publication/2021_tmech_odometry/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tmech_odometry/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;comparison&#34; /&gt;
&lt;small&gt;Comparison of traditional method and the proposed method.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DarkTrack2021</title>
      <link>https://vision4robotics.github.io/project/darktrack2021/</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/project/darktrack2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>UAMT100</title>
      <link>https://vision4robotics.github.io/project/uamt100/</link>
      <pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/project/uamt100/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spatial Reliability Enhanced Correlation Filter: An Efficient Approach for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_tmm_srecf-tracker/</link>
      <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tmm_srecf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;SRECF_workflow&#34; /&gt;
&lt;small&gt;The main workflow of the SRECF tracker.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HiFT: Hierarchical Feature Transformer for Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iccv_hift/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iccv_hift/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;HiFT_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Overview of the HiFT tracker.&lt;/small&gt;
&lt;img src=&#34;comparison.png&#34; alt=&#34;comparison&#34; /&gt;
&lt;small&gt;Fig. 2 Framework of the hierarchical feature transformer.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DarkLighter: Light Up the Darkness for UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_darklighter/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_darklighter/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking performance comparison in a typical dark scene with the
proposed DarkLighter module activated (in red) or not (in pink).&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ReCF: Exploiting Response Reasoning for Correlation Filters in Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_tits_recf_tracker/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tits_recf_tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;ReCF_workflow&#34; /&gt;
&lt;small&gt;Main difference between the proposed ReCF and SRDCF.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SiamAPN&#43;&#43;: Siamese Attentional Aggregation Network for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_iros_siamapn&#43;&#43;/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of the SiamAPN++ tracker.&lt;/small&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Regularized Correlation Filter for UAV Tracking and Self-Localization</title>
      <link>https://vision4robotics.github.io/publication/2021_tie_mrcf_tracker/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tie_mrcf_tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;MRCF_workflow&#34; /&gt;
&lt;small&gt;Overall flowchart of the proposed MRCF.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network</title>
      <link>https://vision4robotics.github.io/publication/2021_tgrs_siamapn_ext/</link>
      <pubDate>Fri, 14 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_tgrs_siamapn_ext/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;SiamAPN_workflow&#34; /&gt;
&lt;small&gt;The workflow of SiamAPN. It is composed of four subnetworks and two stages, i.e., feature extraction network, feature fusion network, anchor proposal network, and classification&amp;amp;regression network. Stage-1 includes feature extraction network and anchor proposal network (APN). Stage-2 contains feature fusion network and classification&amp;amp;regression network.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation</title>
      <link>https://vision4robotics.github.io/publication/2021_grsm_cfmg/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_grsm_cfmg/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;IBRI_workflow&#34; /&gt;
&lt;small&gt;General tracking structure of DCF-based methods onboard the UAV platform, which can be divided into the training stage, model update, and detection stage.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predictive Visual Tracking: A New Benchmark and Baseline Approach</title>
      <link>https://vision4robotics.github.io/publication/2021_arxiv_pvt/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_arxiv_pvt/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;ADTrack_workflow&#34; /&gt;
&lt;small&gt;&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_adtrack/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_adtrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Overall framework of the proposed ADTrack. ADTrack includes 3 stages: pretreatment, training, and detection, which are marked out by boxes in different colors. Dual filters, i.e., context filter and target-focused filter, training and detection follow routes in different colors. It can be seen that the final response shaded noises in context response, which indicates the validity of proposed dual filter.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_mscf_tracker/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_mscf_tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Tracking procedure of the proposed MSCF tracker. Dashed boxes denote the variables to be solved in the main regression. As MTF in the red
box is generated from search region in frame k, it is applied to adjust the altitude value of the cruciform pedestal.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Online Recommendation-based Convolutional Features for Scale-Aware Visual Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_orcf/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_orcf/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of SiamAPN tracker. It composes of four subnetworks, i.e., feature extraction network, feature fusion network, anchor proposal network (APN), and muti-classification®ression network.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Siamese Anchor Proposal Network for High-Speed Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_icra_siamapn/</link>
      <pubDate>Sun, 28 Feb 2021 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_icra_siamapn/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;The overview of SiamAPN tracker. It composes of four subnetworks, i.e., feature extraction network, feature fusion network, anchor proposal network (APN), and muti-classification®ression network.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PVT</title>
      <link>https://vision4robotics.github.io/project/pvt/</link>
      <pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/project/pvt/</guid>
      <description></description>
    </item>
    
    <item>
      <title>All-Day Object Tracking for Unmanned Aerial Vehicle</title>
      <link>https://vision4robotics.github.io/publication/2021_arxiv_adtrack/</link>
      <pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_arxiv_adtrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;ADTrack_workflow&#34; /&gt;
&lt;small&gt;Pipeline of ADTrack.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Dynamic Regression with Automatic Distractor Repression for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2021_eaai_dr2track-tracker/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2021_eaai_dr2track-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;DR2Track_workflow&#34; /&gt;
&lt;small&gt;The object tracking workflow of DR2Track.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UAVDark135</title>
      <link>https://vision4robotics.github.io/project/uavdark135/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/project/uavdark135/</guid>
      <description>

&lt;p&gt;UAVDark135 is the very first UAV dark tracking benchmark dedicated to providing a comprehensive evaluation of tracking performance at night.&lt;/p&gt;

&lt;p&gt;UAVDark135 consists of 135 sequences, most of which were shot by a standard UAV at night, including more than 125k manually annotated frames. The benchmark covers a wide range of scenes, e.g., road, ocean, street, highway, and lakeside, including a large number of objects, such as person, car, building, athlete, truck, and bike.&lt;/p&gt;

&lt;p&gt;The benchmark is available &lt;a href=&#34;https://pan.baidu.com/s/1JcV_wTUSt9F8iBXiLCZQdQ&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; (password: axci).&lt;/p&gt;

&lt;h3 id=&#34;uavdark135-tracking-benchmark&#34;&gt;UAVDark135 Tracking Benchmark&lt;/h3&gt;

&lt;h4 id=&#34;a-platform-and-statistics&#34;&gt;A. Platform and Statistics&lt;/h4&gt;

&lt;p&gt;Standing as the first UAV dark tracking benchmark, the UAVDark135 contains totally 135 sequences captured by a standard UAV2 at night. The benchmark includes various tracking scenes, e.g., crossings, t-junctions, road, highway, and consists of different kinds of tracked objects like people, boat, bus, car, truck, athletes, house, etc. To extent the covered scenes, the benchmark also contains some sequences from YouTube, which were shot on the sea. The total frames, mean frames, maximum frames, and minimum frames of the benchmark are 125466, 929, 4571, and 216 respectively, making it suitable for large-scale evaluation. The videos are captured at a frame-rate of 30 frames/s (FPS), with the resolution of 1920×1080.&lt;/p&gt;

&lt;h4 id=&#34;b-annotation&#34;&gt;B. Annotation&lt;/h4&gt;

&lt;p&gt;The frames in UAVDark135 are all manually annotated, where a sequence is completely processed by the same annotator to ensure consistency. Since in some dark scenes the object is nearly invisible, annotation process is much more strenuous. After the first round, 5 professional annotators carefully checked the results and made revision for several rounds to reduce errors as much as possible in nearly 2 months.&lt;/p&gt;

&lt;p&gt;Since the boundary contour of the object is not obvious in the dark, the result boxes of the first annotation fluctuates in continuous image frames. However, the actual motion process of the object should be smooth. In these considerations, we record the original annotation every 5 frames for the sequence with extremely severe vibration, and the results of the remaining frames are obtained by linear interpolation, which is closer to the position and scale variation of the real object.&lt;/p&gt;

&lt;h4 id=&#34;c-attributes&#34;&gt;C. Attributes&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;image-20210203003923661.png&#34; alt=&#34;image-20210203003923661&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For more details, please refer to our &lt;a href=&#34;https://arxiv.org/abs/2101.08446&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Disruptor-Aware Interval-Based Response Inconsistency for Correlation Filters in Real-Time Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_tgrs_ibri-tracker/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_tgrs_ibri-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.jpg&#34; alt=&#34;IBRI_workflow&#34; /&gt;
&lt;small&gt;Tracking procedure of the proposed IBRI tracker in the k-th frame. Historical interval responses are incorporated into the filter training phase after denoising by a novel disruptor-aware scheme based on response bucketing.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Temporary Block-Based Bidirectional Incongruity-Aware Correlation Filters for Efficient UAV Object Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_tcsvt_tb-bicf-tracker/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_tcsvt_tb-bicf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;TB-BiCF_workflow&#34; /&gt;
&lt;small&gt;A flowchart of the proposed TB-BiCF tracker.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Augmented Memory for Correlation Filters in Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_iros_amcf-tracker/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_iros_amcf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;AMCF_workflow&#34; /&gt;
&lt;small&gt;Overall structure of AMCF.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatic Failure Recovery and Re-Initialization for Online UAV Tracking with Joint Scale and Aspect Ratio Optimization</title>
      <link>https://vision4robotics.github.io/publication/2020_iros_jsar-tracker/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_iros_jsar-tracker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DR^2Track: Towards Real-Time Visual Tracking for UAV via Distractor Repressed Dynamic Regression</title>
      <link>https://vision4robotics.github.io/publication/2020_iros_dr2track-tracker/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_iros_dr2track-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;DR2Track_workflow&#34; /&gt;
&lt;small&gt;Overall work-flow of DR^2Track.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Consistency Pursued Correlation Filters for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_iros_cpcf-tracker/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_iros_cpcf-tracker/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters</title>
      <link>https://vision4robotics.github.io/publication/2020_iros_tacf-tracker/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_iros_tacf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;TACF_workflow&#34; /&gt;
&lt;small&gt;The main workflow of the TACF tracker.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Object Saliency-Aware Dual Regularized Correlation Filter for Real-Time Aerial Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_tgrs_drcf-tracker/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_tgrs_drcf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;DRCF_workflow&#34; /&gt;
&lt;small&gt;Comparison between the tracking pipeline of the baseline SRDCF tracker and the proposed DRCF tracker.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intermittent Contextual Learning for Keyfilter-Aware UAV Object Tracking Using Deep Convolutional Feature</title>
      <link>https://vision4robotics.github.io/publication/2020_tmm_kaot-tracker/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_tmm_kaot-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;KAOT_workflow&#34; /&gt;
&lt;small&gt;Main work-flow of the KAOT tracker.&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization</title>
      <link>https://vision4robotics.github.io/publication/2020_cvpr_autotrack/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_cvpr_autotrack/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;autotrack&#34; /&gt;
&lt;small&gt;Central idea of AutoTrack.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_icra_bicf-tracker/</link>
      <pubDate>Wed, 22 Jan 2020 12:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_icra_bicf-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt; Comparison between discriminative correlation filter (DCF) and the proposed BiCF tracker&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Training-Set Distillation for Real-Time UAV Object Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_icra_tsd-tracker/</link>
      <pubDate>Wed, 22 Jan 2020 08:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_icra_tsd-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Comparison between our TSD tracker with the baseline BACF tracker&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Keyfilter-Aware Real-Time UAV Object Tracking</title>
      <link>https://vision4robotics.github.io/publication/2020_icra_kaot-tracker/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_icra_kaot-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;featured.png&#34; alt=&#34;KAOT_comparision&#34; /&gt;
&lt;small&gt;Comparison between response maps of our tracker and baseline.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters</title>
      <link>https://vision4robotics.github.io/publication/2020_ncaa_mkct-tracker/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2020_ncaa_mkct-tracker/</guid>
      <description>&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Main structure of the proposed MKCT-Tracker&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Surrounding-Aware Correlation Filter for UAV Tracking with Selective Spatial Regularization</title>
      <link>https://vision4robotics.github.io/publication/2019_signal_processing_sasr-tracker/</link>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_signal_processing_sasr-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;SASR_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main workflow of the proposed SASR tracker.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking</title>
      <link>https://vision4robotics.github.io/publication/2019_iccv_arcf-tracker/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_iccv_arcf-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;comparison.png&#34; alt=&#34;comparison&#34; /&gt;
&lt;small&gt;Fig. 1 Comparison between background-aware correlation filter (BACF) and the proposed ARCF tracker.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;ARCF_workflow&#34; /&gt;
&lt;small&gt;Fig. 2 Main structure of the proposed ARCF tracker.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Boundary Effect-Aware Visual Tracking for UAV with Online Enhanced Background Learning and Multi-Frame Consensus Veriﬁcation</title>
      <link>https://vision4robotics.github.io/publication/2019_iros_bevt-tracker/</link>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_iros_bevt-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;BEVT_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main structure of the proposed tracking approach.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Part-Based Background-Aware Tracking for UAV with Convolutional Features</title>
      <link>https://vision4robotics.github.io/publication/2019_ieee_access_pbbat-tracker/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_ieee_access_pbbat-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;PBBAT_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main structure of the proposed tracking approach.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Anticipation: Lightweight Intelligent Mobile Sensing for Unmanned Vehicles in IoT by Recurrent Architecture</title>
      <link>https://vision4robotics.github.io/publication/2019_iet_intell_transp_syst/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_iet_intell_transp_syst/</guid>
      <description>&lt;!--

---

&lt;center&gt;

![SSIM-WMIL_workflow](featured.jpg)
&lt;small&gt;Fig. 1 The closed-loop control structure for the long-term navigation of the quadrotor UAV in real-time application.&lt;/small&gt;

&lt;/center&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>Intuit Before Tuning: Type-1 and Type-2 Fuzzy Logic Controllers</title>
      <link>https://vision4robotics.github.io/publication/2019_appl_soft_comput/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_appl_soft_comput/</guid>
      <description>&lt;!--

---

&lt;center&gt;

![SSIM-WMIL_workflow](featured.jpg)
&lt;small&gt;Fig. 1 The closed-loop control structure for the long-term navigation of the quadrotor UAV in real-time application.&lt;/small&gt;

&lt;/center&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>Correlation Filter-Based Visual Tracking for UAV with Online Multi-Feature Learning</title>
      <link>https://vision4robotics.github.io/publication/2019_remote_sens_omfl-tracker/</link>
      <pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_remote_sens_omfl-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;OMFL_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main structure of the proposed tracking approach.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visual Tracking With Online Structural Similarity-Based Weighted Multiple Instance Learning</title>
      <link>https://vision4robotics.github.io/publication/2019_inf_sci_ssim-wmil/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2019_inf_sci_ssim-wmil/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;SSIM-WMIL_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main structure of the proposed tracking approach.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Scalable Part-Based Visual Tracking for UAV with Background-Aware Correlation Filter</title>
      <link>https://vision4robotics.github.io/publication/2018_robio_spbacf-tracker/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2018_robio_spbacf-tracker/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;SPBACF_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 Main structure of the proposed tracking approach.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Input Uncertainty Sensitivity Enhanced Nonsingleton Fuzzy Logic Controllers for Long-Term Navigation of Quadrotor UAVs</title>
      <link>https://vision4robotics.github.io/publication/2018_tmech/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vision4robotics.github.io/publication/2018_tmech/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.jpg&#34; alt=&#34;SSIM-WMIL_workflow&#34; /&gt;
&lt;small&gt;Fig. 1 The closed-loop control structure for the long-term navigation of the quadrotor UAV in real-time application.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
